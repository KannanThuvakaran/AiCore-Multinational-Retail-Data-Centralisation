{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from sqlalchemy import create_engine, inspect\n",
    "import pandas as pd\n",
    "from dateutil.parser import parse\n",
    "import tabula\n",
    "import requests\n",
    "import json\n",
    "import boto3\n",
    "\n",
    "class DatabaseConnector:\n",
    "    def __init__(self, file=None):\n",
    "        self.file = file\n",
    "        self.db_creds = self.read_db_creds()\n",
    "        self.db_engine = self.init_db_engine()\n",
    "        self.db_table_list = self.list_db_tables()\n",
    "\n",
    "    def read_db_creds(self):\n",
    "        with open(self.file, 'r') as f:\n",
    "            db_creds = yaml.safe_load(f)\n",
    "            return db_creds\n",
    "    \n",
    "    def init_db_engine(self):\n",
    "        db_engine = create_engine(f\"postgresql://{self.db_creds['RDS_USER']}:{self.db_creds['RDS_PASSWORD']}@{self.db_creds['RDS_HOST']}:{self.db_creds['RDS_PORT']}/{self.db_creds['RDS_DATABASE']}\")\n",
    "        return db_engine\n",
    "\n",
    "    def list_db_tables(self):\n",
    "        insp = inspect(self.db_engine)\n",
    "        db_table_list = insp.get_table_names()\n",
    "        return db_table_list\n",
    "    \n",
    "    def upload_to_db(self, clean_dataframe, table_name):\n",
    "        db_to_sql = clean_dataframe.to_sql(table_name, self.db_engine, if_exists='replace', index=False)\n",
    "        return db_to_sql\n",
    "\n",
    "class DataExtractor:\n",
    "    def __init__(self, database=None):\n",
    "        self.database = database\n",
    "\n",
    "    def read_rds_table(self, table_name):\n",
    "        table_data = pd.read_sql_table(table_name, self.database).set_index('index')\n",
    "        return table_data\n",
    "\n",
    "    def retrieve_pdf_data(self, pdf_path):\n",
    "        pdf_df_page = tabula.read_pdf(pdf_path, pages='all')\n",
    "        pdf_df = pd.concat(pdf_df_page, ignore_index=True)\n",
    "        return pdf_df\n",
    "    \n",
    "    def list_number_of_stores(self, number_of_stores_endpoint, header):\n",
    "        response = requests.get(number_of_stores_endpoint, headers=header)\n",
    "        number_of_stores_data = response.json()\n",
    "        return number_of_stores_data['number_stores']\n",
    "    \n",
    "    def retrieve_stores_data(self, store_endpoint, number_of_stores, header):\n",
    "        store_df = []\n",
    "        for store_number in range(number_of_stores):\n",
    "            response = requests.get(f'{store_endpoint}{store_number}', headers=header).json()\n",
    "            store = pd.json_normalize(response)\n",
    "            store_df.append(store)\n",
    "        stores_df = pd.concat(store_df).set_index('index')\n",
    "        return stores_df\n",
    "    \n",
    "    def extract_from_s3(self,s3_path, local_path):\n",
    "        # Split S3 path into bucket and key\n",
    "        bucket, key = s3_path.replace('s3://', '').split('/')   \n",
    "        # Create an S3 client\n",
    "        s3 = boto3.client('s3')\n",
    "        \n",
    "        # Download the file from S3\n",
    "        s3.download_file(bucket, key, local_path)\n",
    "        \n",
    "        # Read the CSV file into a pandas DataFrame\n",
    "        df = pd.read_csv(local_path, index_col=0)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "class DataCleaning:\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "\n",
    "    def clean_user_data(self):\n",
    "        # Remove NULL values and duplicates\n",
    "        self.dataframe = self.dataframe.dropna().drop_duplicates()\n",
    "\n",
    "        # Clean country code\n",
    "        self.dataframe['country_code'] = self.dataframe['country_code'].replace('GGB', 'GB')\n",
    "        self.dataframe = self.dataframe[self.dataframe['country_code'].str.len() == 2]\n",
    "\n",
    "        # Clean dates\n",
    "        self.dataframe.loc[:,'date_of_birth'] = pd.to_datetime(self.dataframe['date_of_birth'].apply(parse))\n",
    "        self.dataframe.loc[:,'join_date'] = pd.to_datetime(self.dataframe['join_date'].apply(parse))\n",
    "\n",
    "        # Clean phone numbers\n",
    "        regex = '^(\\(?\\+?[0-9]*\\)?)?[0-9_\\- \\(\\)]*$'\n",
    "        self.dataframe.loc[:,'phone_number'] = self.dataframe['phone_number'].str.replace('(0)', '', regex=False)\n",
    "        self.dataframe.loc[:,'phone_number'] = self.dataframe['phone_number'].replace(r'\\D+', '', regex=True)\n",
    "\n",
    "        return self.dataframe\n",
    "\n",
    "    def clean_card_data(self):\n",
    "        card_provider_list = ['Diners Club / Carte Blanche', 'American Express', 'JCB 16 digit',\n",
    "                             'JCB 15 digit', 'Maestro', 'Mastercard', 'Discover',\n",
    "                             'VISA 19 digit', 'VISA 16 digit', 'VISA 13 digit']\n",
    "\n",
    "        # Filter card data based on card providers\n",
    "        self.dataframe = self.dataframe[self.dataframe['card_provider'].isin(card_provider_list)]\n",
    "\n",
    "        # Clean and format date columns\n",
    "        self.dataframe.loc[:,'expiry_date'] = pd.to_datetime(self.dataframe['expiry_date'], errors='coerce', format='%m/%y')\n",
    "        self.dataframe.loc[:,'date_payment_confirmed'] = pd.to_datetime(self.dataframe['date_payment_confirmed'], errors='coerce', format='%Y-%m-%d')\n",
    "\n",
    "        # Drop NULL values and duplicates\n",
    "        self.dataframe = self.dataframe.dropna().drop_duplicates()\n",
    "\n",
    "        return self.dataframe\n",
    "\n",
    "    def clean_store_data(self):\n",
    "        self.dataframe = self.dataframe[self.dataframe['country_code'].str.len() == 2]\n",
    "        self.dataframe.loc[:, 'opening_date'] = pd.to_datetime(self.dataframe['opening_date'], errors='coerce', format='%Y-%m-%d')\n",
    "\n",
    "        self.dataframe.loc[:, 'continent'] = self.dataframe['continent'].replace(['eeEurope', 'eeAmerica'], ['Europe', 'America'])\n",
    "\n",
    "        self.dataframe = self.dataframe.drop(columns='lat')\n",
    "        self.dataframe['staff_numbers'] = self.dataframe['staff_numbers'].apply(lambda x: \"\".join(filter(str.isdigit, str(x))))\n",
    "\n",
    "        self.dataframe = self.dataframe.dropna().drop_duplicates()\n",
    "\n",
    "        return self.dataframe\n",
    "        \n",
    "    def convert_product_weights(self):\n",
    "        replacements = {\n",
    "            'kg': '',\n",
    "            'g': '/1000',\n",
    "            'ml': '/1000',\n",
    "            'x': '*',\n",
    "            'oz': '/35.274',\n",
    "            '77/1000 .': '77/1000'\n",
    "        }\n",
    "    \n",
    "        self.dataframe['weight'] = self.dataframe['weight'].replace(replacements, regex=True)\n",
    "        self.dataframe['weight'] = self.dataframe['weight'].str.replace('77/1000 .', '77/1000', regex=True)\n",
    "        self.dataframe['weight'] = self.dataframe['weight'].apply(lambda x: eval(str(x))).astype(float)\n",
    "        return self.dataframe\n",
    "\n",
    "    def clean_products_data(self):\n",
    "        self.dataframe.loc[:,'removed'] = self.dataframe['removed'].str.replace('Still_avaliable', 'Still_available')\n",
    "        self.dataframe = self.dataframe[self.dataframe['removed'].isin(['Still_available', 'Removed'])]\n",
    "        self.dataframe = self.convert_product_weights()\n",
    "        return self.dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_database = DatabaseConnector(file='db_creds.yaml').init_db_engine()\n",
    "user_data_df = DataExtractor(yaml_database).read_rds_table('legacy_users')\n",
    "cleaned_df = DataCleaning(user_data_df).clean_user_data()\n",
    "user_data_to_sql = DatabaseConnector(file='sales_data_creds.yaml').upload_to_db(cleaned_df, 'dim_users')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_file = DataExtractor().retrieve_pdf_data(\"https://data-handling-public.s3.eu-west-1.amazonaws.com/card_details.pdf\")\n",
    "data_pdf = DataCleaning(dataframe=pdf_file).clean_card_data()\n",
    "card_details_to_sql = DatabaseConnector(file='sales_data_creds.yaml').upload_to_db(data_pdf, 'dim_card_details')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>longitude</th>\n",
       "      <th>lat</th>\n",
       "      <th>locality</th>\n",
       "      <th>store_code</th>\n",
       "      <th>staff_numbers</th>\n",
       "      <th>opening_date</th>\n",
       "      <th>store_type</th>\n",
       "      <th>latitude</th>\n",
       "      <th>country_code</th>\n",
       "      <th>continent</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>WEB-1388012W</td>\n",
       "      <td>325</td>\n",
       "      <td>2010-06-12</td>\n",
       "      <td>Web Portal</td>\n",
       "      <td>None</td>\n",
       "      <td>GB</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Flat 72W\\nSally isle\\nEast Deantown\\nE7B 8EB, ...</td>\n",
       "      <td>51.62907</td>\n",
       "      <td>None</td>\n",
       "      <td>High Wycombe</td>\n",
       "      <td>HI-9B97EE4E</td>\n",
       "      <td>34</td>\n",
       "      <td>1996-10-25</td>\n",
       "      <td>Local</td>\n",
       "      <td>-0.74934</td>\n",
       "      <td>GB</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Heckerstraße 4/5\\n50491 Säckingen, Landshut</td>\n",
       "      <td>48.52961</td>\n",
       "      <td>None</td>\n",
       "      <td>Landshut</td>\n",
       "      <td>LA-0772C7B9</td>\n",
       "      <td>92</td>\n",
       "      <td>2013-04-12</td>\n",
       "      <td>Super Store</td>\n",
       "      <td>12.16179</td>\n",
       "      <td>DE</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5 Harrison tunnel\\nSouth Lydia\\nWC9 2BE, Westbury</td>\n",
       "      <td>51.26</td>\n",
       "      <td>None</td>\n",
       "      <td>Westbury</td>\n",
       "      <td>WE-1DE82CEE</td>\n",
       "      <td>69</td>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>Super Store</td>\n",
       "      <td>-2.1875</td>\n",
       "      <td>GB</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Studio 6\\nStephen landing\\nSouth Simon\\nB77 2W...</td>\n",
       "      <td>53.0233</td>\n",
       "      <td>None</td>\n",
       "      <td>Belper</td>\n",
       "      <td>BE-18074576</td>\n",
       "      <td>35</td>\n",
       "      <td>2019-09-09</td>\n",
       "      <td>Local</td>\n",
       "      <td>-1.48119</td>\n",
       "      <td>GB</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>Täschestraße 25\\n39039 Nördlingen, Kirchlengern</td>\n",
       "      <td>52.2</td>\n",
       "      <td>None</td>\n",
       "      <td>Kirchlengern</td>\n",
       "      <td>KI-78096E8C</td>\n",
       "      <td>61</td>\n",
       "      <td>2005-05-12</td>\n",
       "      <td>Super Store</td>\n",
       "      <td>8.63333</td>\n",
       "      <td>DE</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>K0ODETRLS3</td>\n",
       "      <td>K8CXLZDP07</td>\n",
       "      <td>UXMWDMX1LC</td>\n",
       "      <td>3VHFDNP8ET</td>\n",
       "      <td>9D4LK7X4LZ</td>\n",
       "      <td>D23PCWSM6S</td>\n",
       "      <td>36IIMAQD58</td>\n",
       "      <td>NN04B3F6UQ</td>\n",
       "      <td>JZP8MIJTPZ</td>\n",
       "      <td>B3EH2ZGQAV</td>\n",
       "      <td>1WZB1TE1HL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>Studio 8\\nMoss mall\\nWest Linda\\nM0E 6XR, High...</td>\n",
       "      <td>51.62907</td>\n",
       "      <td>None</td>\n",
       "      <td>High Wycombe</td>\n",
       "      <td>HI-EEA7AE62</td>\n",
       "      <td>33</td>\n",
       "      <td>1998-05-14</td>\n",
       "      <td>Local</td>\n",
       "      <td>-0.74934</td>\n",
       "      <td>GB</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>Baumplatz 6\\n80114 Kötzting, Bretten</td>\n",
       "      <td>49.03685</td>\n",
       "      <td>None</td>\n",
       "      <td>Bretten</td>\n",
       "      <td>BR-662EC74C</td>\n",
       "      <td>35</td>\n",
       "      <td>2020-10-17</td>\n",
       "      <td>Local</td>\n",
       "      <td>8.70745</td>\n",
       "      <td>DE</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>Gotthilf-Rose-Straße 7/3\\n45457 Feuchtwangen, ...</td>\n",
       "      <td>50.64336</td>\n",
       "      <td>None</td>\n",
       "      <td>Bad Honnef</td>\n",
       "      <td>BA-B4AED588</td>\n",
       "      <td>36</td>\n",
       "      <td>2001-05-12</td>\n",
       "      <td>Local</td>\n",
       "      <td>7.2278</td>\n",
       "      <td>DE</td>\n",
       "      <td>eeEurope</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>451 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 address   longitude  \\\n",
       "index                                                                  \n",
       "0                                                    N/A         N/A   \n",
       "1      Flat 72W\\nSally isle\\nEast Deantown\\nE7B 8EB, ...    51.62907   \n",
       "2            Heckerstraße 4/5\\n50491 Säckingen, Landshut    48.52961   \n",
       "3      5 Harrison tunnel\\nSouth Lydia\\nWC9 2BE, Westbury       51.26   \n",
       "4      Studio 6\\nStephen landing\\nSouth Simon\\nB77 2W...     53.0233   \n",
       "...                                                  ...         ...   \n",
       "446      Täschestraße 25\\n39039 Nördlingen, Kirchlengern        52.2   \n",
       "447                                           K0ODETRLS3  K8CXLZDP07   \n",
       "448    Studio 8\\nMoss mall\\nWest Linda\\nM0E 6XR, High...    51.62907   \n",
       "449                 Baumplatz 6\\n80114 Kötzting, Bretten    49.03685   \n",
       "450    Gotthilf-Rose-Straße 7/3\\n45457 Feuchtwangen, ...    50.64336   \n",
       "\n",
       "              lat      locality    store_code staff_numbers opening_date  \\\n",
       "index                                                                      \n",
       "0             N/A           N/A  WEB-1388012W           325   2010-06-12   \n",
       "1            None  High Wycombe   HI-9B97EE4E            34   1996-10-25   \n",
       "2            None      Landshut   LA-0772C7B9            92   2013-04-12   \n",
       "3            None      Westbury   WE-1DE82CEE            69   2014-01-02   \n",
       "4            None        Belper   BE-18074576            35   2019-09-09   \n",
       "...           ...           ...           ...           ...          ...   \n",
       "446          None  Kirchlengern   KI-78096E8C            61   2005-05-12   \n",
       "447    UXMWDMX1LC    3VHFDNP8ET    9D4LK7X4LZ    D23PCWSM6S   36IIMAQD58   \n",
       "448          None  High Wycombe   HI-EEA7AE62            33   1998-05-14   \n",
       "449          None       Bretten   BR-662EC74C            35   2020-10-17   \n",
       "450          None    Bad Honnef   BA-B4AED588            36   2001-05-12   \n",
       "\n",
       "        store_type    latitude country_code   continent  \n",
       "index                                                    \n",
       "0       Web Portal        None           GB      Europe  \n",
       "1            Local    -0.74934           GB      Europe  \n",
       "2      Super Store    12.16179           DE      Europe  \n",
       "3      Super Store     -2.1875           GB      Europe  \n",
       "4            Local    -1.48119           GB      Europe  \n",
       "...            ...         ...          ...         ...  \n",
       "446    Super Store     8.63333           DE      Europe  \n",
       "447     NN04B3F6UQ  JZP8MIJTPZ   B3EH2ZGQAV  1WZB1TE1HL  \n",
       "448          Local    -0.74934           GB      Europe  \n",
       "449          Local     8.70745           DE      Europe  \n",
       "450          Local      7.2278           DE    eeEurope  \n",
       "\n",
       "[451 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = {'x-api-key': 'yFBQbwXe9J3sd6zWVAMrK6lcxxr0q1lr2PT6DDMX'}\n",
    "\n",
    "number_of_stores = DataExtractor().list_number_of_stores('https://aqj7u5id95.execute-api.eu-west-1.amazonaws.com/prod/number_stores', headers)\n",
    "stores_data = DataExtractor().retrieve_stores_data(f'https://aqj7u5id95.execute-api.eu-west-1.amazonaws.com/prod/store_details/', number_of_stores, headers)\n",
    "\n",
    "stores_data_clean = DataCleaning(stores_data).clean_store_data()\n",
    "store_data_to_sql = DatabaseConnector('sales_data_creds.yaml').upload_to_db(stores_data_clean, 'dim_store_details')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import s3fs\n",
    "#def extract_from_s3(s3_resource):\n",
    "    #df = pd.read_csv(s3_resource, index_col=0)\n",
    "    #return df\n",
    "\n",
    "#s3_df = extract_from_s3('s3://data-handling-public/products.csv')\n",
    "#s3_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kthuv\\AppData\\Local\\Temp\\ipykernel_17116\\1917274190.py:140: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.dataframe['weight'] = self.dataframe['weight'].replace(replacements, regex=True)\n",
      "C:\\Users\\kthuv\\AppData\\Local\\Temp\\ipykernel_17116\\1917274190.py:141: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.dataframe['weight'] = self.dataframe['weight'].str.replace('77/1000 .', '77/1000', regex=True)\n",
      "C:\\Users\\kthuv\\AppData\\Local\\Temp\\ipykernel_17116\\1917274190.py:142: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.dataframe['weight'] = self.dataframe['weight'].apply(lambda x: eval(str(x))).astype(float)\n"
     ]
    }
   ],
   "source": [
    "# Use the local_path in the function\n",
    "s3_df = DataExtractor().extract_from_s3('s3://data-handling-public/products.csv', local_path = '/Users/kthuv/AiCore/Projects/MRDC/products.csv')\n",
    "\n",
    "s3_data_df = DataCleaning(s3_df).clean_products_data()\n",
    "\n",
    "products_df = DatabaseConnector(file='sales_data_creds.yaml').upload_to_db(s3_data_df, 'dim_products')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mrdc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

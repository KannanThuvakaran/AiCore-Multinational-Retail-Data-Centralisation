{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from sqlalchemy import create_engine, inspect\n",
    "import pandas as pd\n",
    "from dateutil.parser import parse\n",
    "import tabula\n",
    "import requests\n",
    "import json\n",
    "import boto3\n",
    "\n",
    "class DatabaseConnector:\n",
    "    def __init__(self, file=None):\n",
    "        self.file = file\n",
    "        self.db_creds = self.read_db_creds()\n",
    "        self.db_engine = self.init_db_engine()\n",
    "        self.db_table_list = self.list_db_tables()\n",
    "\n",
    "    def read_db_creds(self):\n",
    "        with open(self.file, 'r') as f:\n",
    "            db_creds = yaml.safe_load(f)\n",
    "            return db_creds\n",
    "    \n",
    "    def init_db_engine(self):\n",
    "        db_engine = create_engine(f\"postgresql://{self.db_creds['RDS_USER']}:{self.db_creds['RDS_PASSWORD']}@{self.db_creds['RDS_HOST']}:{self.db_creds['RDS_PORT']}/{self.db_creds['RDS_DATABASE']}\")\n",
    "        return db_engine\n",
    "\n",
    "    def list_db_tables(self):\n",
    "        insp = inspect(self.db_engine)\n",
    "        db_table_list = insp.get_table_names()\n",
    "        return db_table_list\n",
    "    \n",
    "    def upload_to_db(self, clean_dataframe, table_name):\n",
    "        db_to_sql = clean_dataframe.to_sql(table_name, self.db_engine, if_exists='replace', index=False)\n",
    "        return db_to_sql\n",
    "\n",
    "class DataExtractor:\n",
    "    def __init__(self, database=None):\n",
    "        self.database = database\n",
    "\n",
    "    def read_rds_table(self, table_name):\n",
    "        table_data = pd.read_sql_table(table_name, self.database).set_index('index')\n",
    "        return table_data\n",
    "\n",
    "    def retrieve_pdf_data(self, pdf_path):\n",
    "        pdf_df_page = tabula.read_pdf(pdf_path, pages='all')\n",
    "        pdf_df = pd.concat(pdf_df_page, ignore_index=True)\n",
    "        return pdf_df\n",
    "    \n",
    "    def list_number_of_stores(self, number_of_stores_endpoint, header):\n",
    "        response = requests.get(number_of_stores_endpoint, headers=header)\n",
    "        number_of_stores_data = response.json()\n",
    "        return number_of_stores_data['number_stores']\n",
    "    \n",
    "    def retrieve_stores_data(self, store_endpoint, number_of_stores, header):\n",
    "        store_df = []\n",
    "        for store_number in range(number_of_stores):\n",
    "            response = requests.get(f'{store_endpoint}{store_number}', headers=header).json()\n",
    "            store = pd.json_normalize(response)\n",
    "            store_df.append(store)\n",
    "        stores_df = pd.concat(store_df).set_index('index')\n",
    "        return stores_df\n",
    "    \n",
    "    def extract_from_s3_csv(self,s3_path, local_path):\n",
    "        # Split S3 path into bucket and key\n",
    "        bucket, key = s3_path.replace('s3://', '').split('/')   \n",
    "        # Create an S3 client\n",
    "        s3 = boto3.client('s3')\n",
    "        \n",
    "        # Download the file from S3\n",
    "        s3.download_file(bucket, key, local_path)\n",
    "        \n",
    "        # Read the CSV file into a pandas DataFrame\n",
    "        df = pd.read_csv(local_path, index_col=0)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def extract_from_s3_json(self,s3_path, local_path):\n",
    "        # Split S3 path into bucket and key\n",
    "        bucket, key = s3_path.replace('s3://', '').split('/')   \n",
    "        # Create an S3 client\n",
    "        s3 = boto3.client('s3')\n",
    "        \n",
    "        # Download the file from S3\n",
    "        s3.download_file(bucket, key, local_path)\n",
    "        \n",
    "        # Read the CSV file into a pandas DataFrame\n",
    "        df = pd.read_json(local_path)\n",
    "        return df\n",
    "    \n",
    "class DataCleaning:\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "\n",
    "    def clean_user_data(self):\n",
    "        # Remove NULL values and duplicates\n",
    "        self.dataframe = self.dataframe.dropna().drop_duplicates()\n",
    "\n",
    "        # Clean country code\n",
    "        self.dataframe['country_code'] = self.dataframe['country_code'].replace('GGB', 'GB')\n",
    "        self.dataframe = self.dataframe[self.dataframe['country_code'].str.len() == 2]\n",
    "\n",
    "        # Clean dates\n",
    "        self.dataframe.loc[:,'date_of_birth'] = pd.to_datetime(self.dataframe['date_of_birth'].apply(parse))\n",
    "        self.dataframe.loc[:,'join_date'] = pd.to_datetime(self.dataframe['join_date'].apply(parse))\n",
    "\n",
    "        # Clean phone numbers\n",
    "        regex = '^(\\(?\\+?[0-9]*\\)?)?[0-9_\\- \\(\\)]*$'\n",
    "        self.dataframe.loc[:,'phone_number'] = self.dataframe['phone_number'].str.replace('(0)', '', regex=False)\n",
    "        self.dataframe.loc[:,'phone_number'] = self.dataframe['phone_number'].replace(r'\\D+', '', regex=True)\n",
    "\n",
    "        return self.dataframe\n",
    "\n",
    "    def clean_card_data(self):\n",
    "        card_provider_list = ['Diners Club / Carte Blanche', 'American Express', 'JCB 16 digit',\n",
    "                             'JCB 15 digit', 'Maestro', 'Mastercard', 'Discover',\n",
    "                             'VISA 19 digit', 'VISA 16 digit', 'VISA 13 digit']\n",
    "\n",
    "\n",
    "        # Filter card data based on card providers\n",
    "        self.dataframe = self.dataframe[self.dataframe['card_provider'].isin(card_provider_list)]\n",
    "\n",
    "        # Clean and format date columns\n",
    "        self.dataframe.loc[:,'expiry_date'] = pd.to_datetime(self.dataframe['expiry_date'], errors = 'coerce', format='%m-%y')\n",
    "        self.dataframe.loc[:,'date_payment_confirmed'] = pd.to_datetime(self.dataframe['date_payment_confirmed'], format='mixed')\n",
    "        self.dataframe.loc[:, 'card_number'] = self.dataframe['card_number'].apply(lambda x: \"\".join(filter(str.isdigit, str(x)))) \n",
    "\n",
    "        # Drop NULL values and duplicates\n",
    "        self.dataframe = self.dataframe.drop_duplicates()\n",
    "\n",
    "        return self.dataframe\n",
    "\n",
    "    def clean_store_data(self):\n",
    "        self.dataframe = self.dataframe[self.dataframe['country_code'].str.len() == 2]\n",
    "        self.dataframe.loc[:, 'opening_date'] = pd.to_datetime(self.dataframe['opening_date'], errors='coerce', format='%Y-%m-%d')\n",
    "\n",
    "        self.dataframe.loc[:, 'continent'] = self.dataframe['continent'].replace(['eeEurope', 'eeAmerica'], ['Europe', 'America'])\n",
    "\n",
    "        self.dataframe = self.dataframe.drop(columns='lat')\n",
    "        self.dataframe['staff_numbers'] = self.dataframe['staff_numbers'].apply(lambda x: \"\".join(filter(str.isdigit, str(x))))\n",
    "\n",
    "        self.dataframe = self.dataframe.drop_duplicates()\n",
    "\n",
    "        return self.dataframe\n",
    "        \n",
    "    def convert_product_weights(self):\n",
    "        replacements = {\n",
    "            'kg': '',\n",
    "            'g': '/1000',\n",
    "            'ml': '/1000',\n",
    "            'x': '*',\n",
    "            'oz': '/35.274',\n",
    "            '77/1000 .': '77/1000'\n",
    "        }\n",
    "    \n",
    "        self.dataframe['weight'] = self.dataframe['weight'].replace(replacements, regex=True)\n",
    "        self.dataframe['weight'] = self.dataframe['weight'].str.replace('77/1000 .', '77/1000', regex=True)\n",
    "        self.dataframe['weight'] = self.dataframe['weight'].apply(lambda x: eval(str(x))).astype(float)\n",
    "        return self.dataframe\n",
    "\n",
    "    def clean_products_data(self):\n",
    "        self.dataframe.loc[:,'removed'] = self.dataframe['removed'].str.replace('Still_avaliable', 'Still_available')\n",
    "        self.dataframe = self.dataframe[self.dataframe['removed'].isin(['Still_available', 'Removed'])]\n",
    "        self.dataframe.loc[:, 'date_added'] = pd.to_datetime(self.dataframe['date_added'], errors='coerce', format='%Y-%m-%d')\n",
    "        self.dataframe = self.convert_product_weights()\n",
    "        return self.dataframe\n",
    "    \n",
    "    def clean_orders_data(self):\n",
    "        self.dataframe = self.dataframe.drop(columns=['level_0', 'first_name', 'last_name', '1'])\n",
    "        self.dataframe = self.dataframe.drop_duplicates()\n",
    "        return self.dataframe\n",
    "    \n",
    "    def clean_date_times(self):\n",
    "        self.dataframe = self.dataframe[self.dataframe['day'].apply(lambda x: len(str(x)) <= 2)]\n",
    "        self.dataframe = self.dataframe.dropna().drop_duplicates()\n",
    "        return self.dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_database = DatabaseConnector(file='db_creds.yaml').init_db_engine()\n",
    "user_data_df = DataExtractor(yaml_database).read_rds_table('legacy_users')\n",
    "cleaned_df = DataCleaning(user_data_df).clean_user_data()\n",
    "user_data_to_sql = DatabaseConnector(file='sales_data_creds.yaml').upload_to_db(cleaned_df, 'dim_users_table')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "(psycopg2.errors.DependentObjectsStillExist) cannot drop table dim_card_details because other objects depend on it\nDETAIL:  constraint orders_card_number_id on table orders_table depends on table dim_card_details\nHINT:  Use DROP ... CASCADE to drop the dependent objects too.\n\n[SQL: \nDROP TABLE dim_card_details]\n(Background on this error at: https://sqlalche.me/e/20/2j85)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDependentObjectsStillExist\u001b[0m                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\kthuv\\.conda\\envs\\mrdc\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1965\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[1;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[0;32m   1964\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m evt_handled:\n\u001b[1;32m-> 1965\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdialect\u001b[39m.\u001b[39;49mdo_execute(\n\u001b[0;32m   1966\u001b[0m             cursor, str_statement, effective_parameters, context\n\u001b[0;32m   1967\u001b[0m         )\n\u001b[0;32m   1969\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_events \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine\u001b[39m.\u001b[39m_has_events:\n",
      "File \u001b[1;32mc:\\Users\\kthuv\\.conda\\envs\\mrdc\\Lib\\site-packages\\sqlalchemy\\engine\\default.py:921\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[1;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[0;32m    920\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdo_execute\u001b[39m(\u001b[39mself\u001b[39m, cursor, statement, parameters, context\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m--> 921\u001b[0m     cursor\u001b[39m.\u001b[39;49mexecute(statement, parameters)\n",
      "\u001b[1;31mDependentObjectsStillExist\u001b[0m: cannot drop table dim_card_details because other objects depend on it\nDETAIL:  constraint orders_card_number_id on table orders_table depends on table dim_card_details\nHINT:  Use DROP ... CASCADE to drop the dependent objects too.\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\kthuv\\AiCore\\Projects\\MRDC\\practice.ipynb Cell 3\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kthuv/AiCore/Projects/MRDC/practice.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m pdf_file \u001b[39m=\u001b[39m DataExtractor()\u001b[39m.\u001b[39mretrieve_pdf_data(\u001b[39m\"\u001b[39m\u001b[39mhttps://data-handling-public.s3.eu-west-1.amazonaws.com/card_details.pdf\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kthuv/AiCore/Projects/MRDC/practice.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m data_pdf \u001b[39m=\u001b[39m DataCleaning(dataframe\u001b[39m=\u001b[39mpdf_file)\u001b[39m.\u001b[39mclean_card_data()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/kthuv/AiCore/Projects/MRDC/practice.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m card_details_to_sql \u001b[39m=\u001b[39m DatabaseConnector(file\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msales_data_creds.yaml\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49mupload_to_db(data_pdf, \u001b[39m'\u001b[39;49m\u001b[39mdim_card_details\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\kthuv\\AiCore\\Projects\\MRDC\\practice.ipynb Cell 3\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kthuv/AiCore/Projects/MRDC/practice.ipynb#W2sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mupload_to_db\u001b[39m(\u001b[39mself\u001b[39m, clean_dataframe, table_name):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/kthuv/AiCore/Projects/MRDC/practice.ipynb#W2sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     db_to_sql \u001b[39m=\u001b[39m clean_dataframe\u001b[39m.\u001b[39;49mto_sql(table_name, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdb_engine, if_exists\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mreplace\u001b[39;49m\u001b[39m'\u001b[39;49m, index\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kthuv/AiCore/Projects/MRDC/practice.ipynb#W2sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m db_to_sql\n",
      "File \u001b[1;32mc:\\Users\\kthuv\\.conda\\envs\\mrdc\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\kthuv\\.conda\\envs\\mrdc\\Lib\\site-packages\\pandas\\core\\generic.py:3008\u001b[0m, in \u001b[0;36mNDFrame.to_sql\u001b[1;34m(self, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[0;32m   2813\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   2814\u001b[0m \u001b[39mWrite records stored in a DataFrame to a SQL database.\u001b[39;00m\n\u001b[0;32m   2815\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3004\u001b[0m \u001b[39m[(1,), (None,), (2,)]\u001b[39;00m\n\u001b[0;32m   3005\u001b[0m \u001b[39m\"\"\"\u001b[39;00m  \u001b[39m# noqa: E501\u001b[39;00m\n\u001b[0;32m   3006\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m \u001b[39mimport\u001b[39;00m sql\n\u001b[1;32m-> 3008\u001b[0m \u001b[39mreturn\u001b[39;00m sql\u001b[39m.\u001b[39;49mto_sql(\n\u001b[0;32m   3009\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   3010\u001b[0m     name,\n\u001b[0;32m   3011\u001b[0m     con,\n\u001b[0;32m   3012\u001b[0m     schema\u001b[39m=\u001b[39;49mschema,\n\u001b[0;32m   3013\u001b[0m     if_exists\u001b[39m=\u001b[39;49mif_exists,\n\u001b[0;32m   3014\u001b[0m     index\u001b[39m=\u001b[39;49mindex,\n\u001b[0;32m   3015\u001b[0m     index_label\u001b[39m=\u001b[39;49mindex_label,\n\u001b[0;32m   3016\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[0;32m   3017\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m   3018\u001b[0m     method\u001b[39m=\u001b[39;49mmethod,\n\u001b[0;32m   3019\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\kthuv\\.conda\\envs\\mrdc\\Lib\\site-packages\\pandas\\io\\sql.py:788\u001b[0m, in \u001b[0;36mto_sql\u001b[1;34m(frame, name, con, schema, if_exists, index, index_label, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[0;32m    783\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    784\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mframe\u001b[39m\u001b[39m'\u001b[39m\u001b[39m argument should be either a Series or a DataFrame\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    785\u001b[0m     )\n\u001b[0;32m    787\u001b[0m \u001b[39mwith\u001b[39;00m pandasSQL_builder(con, schema\u001b[39m=\u001b[39mschema, need_transaction\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39mas\u001b[39;00m pandas_sql:\n\u001b[1;32m--> 788\u001b[0m     \u001b[39mreturn\u001b[39;00m pandas_sql\u001b[39m.\u001b[39;49mto_sql(\n\u001b[0;32m    789\u001b[0m         frame,\n\u001b[0;32m    790\u001b[0m         name,\n\u001b[0;32m    791\u001b[0m         if_exists\u001b[39m=\u001b[39;49mif_exists,\n\u001b[0;32m    792\u001b[0m         index\u001b[39m=\u001b[39;49mindex,\n\u001b[0;32m    793\u001b[0m         index_label\u001b[39m=\u001b[39;49mindex_label,\n\u001b[0;32m    794\u001b[0m         schema\u001b[39m=\u001b[39;49mschema,\n\u001b[0;32m    795\u001b[0m         chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[0;32m    796\u001b[0m         dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    797\u001b[0m         method\u001b[39m=\u001b[39;49mmethod,\n\u001b[0;32m    798\u001b[0m         engine\u001b[39m=\u001b[39;49mengine,\n\u001b[0;32m    799\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mengine_kwargs,\n\u001b[0;32m    800\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\kthuv\\.conda\\envs\\mrdc\\Lib\\site-packages\\pandas\\io\\sql.py:1948\u001b[0m, in \u001b[0;36mSQLDatabase.to_sql\u001b[1;34m(self, frame, name, if_exists, index, index_label, schema, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[0;32m   1898\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1899\u001b[0m \u001b[39mWrite records stored in a DataFrame to a SQL database.\u001b[39;00m\n\u001b[0;32m   1900\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1944\u001b[0m \u001b[39m    Any additional kwargs are passed to the engine.\u001b[39;00m\n\u001b[0;32m   1945\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1946\u001b[0m sql_engine \u001b[39m=\u001b[39m get_engine(engine)\n\u001b[1;32m-> 1948\u001b[0m table \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprep_table(\n\u001b[0;32m   1949\u001b[0m     frame\u001b[39m=\u001b[39;49mframe,\n\u001b[0;32m   1950\u001b[0m     name\u001b[39m=\u001b[39;49mname,\n\u001b[0;32m   1951\u001b[0m     if_exists\u001b[39m=\u001b[39;49mif_exists,\n\u001b[0;32m   1952\u001b[0m     index\u001b[39m=\u001b[39;49mindex,\n\u001b[0;32m   1953\u001b[0m     index_label\u001b[39m=\u001b[39;49mindex_label,\n\u001b[0;32m   1954\u001b[0m     schema\u001b[39m=\u001b[39;49mschema,\n\u001b[0;32m   1955\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m   1956\u001b[0m )\n\u001b[0;32m   1958\u001b[0m total_inserted \u001b[39m=\u001b[39m sql_engine\u001b[39m.\u001b[39minsert_records(\n\u001b[0;32m   1959\u001b[0m     table\u001b[39m=\u001b[39mtable,\n\u001b[0;32m   1960\u001b[0m     con\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcon,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1967\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mengine_kwargs,\n\u001b[0;32m   1968\u001b[0m )\n\u001b[0;32m   1970\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_case_sensitive(name\u001b[39m=\u001b[39mname, schema\u001b[39m=\u001b[39mschema)\n",
      "File \u001b[1;32mc:\\Users\\kthuv\\.conda\\envs\\mrdc\\Lib\\site-packages\\pandas\\io\\sql.py:1852\u001b[0m, in \u001b[0;36mSQLDatabase.prep_table\u001b[1;34m(self, frame, name, if_exists, index, index_label, schema, dtype)\u001b[0m\n\u001b[0;32m   1840\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe type of \u001b[39m\u001b[39m{\u001b[39;00mcol\u001b[39m}\u001b[39;00m\u001b[39m is not a SQLAlchemy type\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1842\u001b[0m table \u001b[39m=\u001b[39m SQLTable(\n\u001b[0;32m   1843\u001b[0m     name,\n\u001b[0;32m   1844\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1850\u001b[0m     dtype\u001b[39m=\u001b[39mdtype,\n\u001b[0;32m   1851\u001b[0m )\n\u001b[1;32m-> 1852\u001b[0m table\u001b[39m.\u001b[39;49mcreate()\n\u001b[0;32m   1853\u001b[0m \u001b[39mreturn\u001b[39;00m table\n",
      "File \u001b[1;32mc:\\Users\\kthuv\\.conda\\envs\\mrdc\\Lib\\site-packages\\pandas\\io\\sql.py:929\u001b[0m, in \u001b[0;36mSQLTable.create\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTable \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m already exists.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    928\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mif_exists \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mreplace\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 929\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpd_sql\u001b[39m.\u001b[39;49mdrop_table(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mschema)\n\u001b[0;32m    930\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_execute_create()\n\u001b[0;32m    931\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mif_exists \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mappend\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\kthuv\\.conda\\envs\\mrdc\\Lib\\site-packages\\pandas\\io\\sql.py:2003\u001b[0m, in \u001b[0;36mSQLDatabase.drop_table\u001b[1;34m(self, table_name, schema)\u001b[0m\n\u001b[0;32m   1999\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmeta\u001b[39m.\u001b[39mreflect(\n\u001b[0;32m   2000\u001b[0m     bind\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcon, only\u001b[39m=\u001b[39m[table_name], schema\u001b[39m=\u001b[39mschema, views\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   2001\u001b[0m )\n\u001b[0;32m   2002\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_transaction():\n\u001b[1;32m-> 2003\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_table(table_name, schema)\u001b[39m.\u001b[39;49mdrop(bind\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcon)\n\u001b[0;32m   2004\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmeta\u001b[39m.\u001b[39mclear()\n",
      "File \u001b[1;32mc:\\Users\\kthuv\\.conda\\envs\\mrdc\\Lib\\site-packages\\sqlalchemy\\sql\\schema.py:1305\u001b[0m, in \u001b[0;36mTable.drop\u001b[1;34m(self, bind, checkfirst)\u001b[0m\n\u001b[0;32m   1295\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdrop\u001b[39m(\u001b[39mself\u001b[39m, bind: _CreateDropBind, checkfirst: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1296\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Issue a ``DROP`` statement for this\u001b[39;00m\n\u001b[0;32m   1297\u001b[0m \u001b[39m    :class:`_schema.Table`, using the given\u001b[39;00m\n\u001b[0;32m   1298\u001b[0m \u001b[39m    :class:`.Connection` or :class:`.Engine` for connectivity.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1303\u001b[0m \n\u001b[0;32m   1304\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1305\u001b[0m     bind\u001b[39m.\u001b[39;49m_run_ddl_visitor(ddl\u001b[39m.\u001b[39;49mSchemaDropper, \u001b[39mself\u001b[39;49m, checkfirst\u001b[39m=\u001b[39;49mcheckfirst)\n",
      "File \u001b[1;32mc:\\Users\\kthuv\\.conda\\envs\\mrdc\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:2443\u001b[0m, in \u001b[0;36mConnection._run_ddl_visitor\u001b[1;34m(self, visitorcallable, element, **kwargs)\u001b[0m\n\u001b[0;32m   2431\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_ddl_visitor\u001b[39m(\n\u001b[0;32m   2432\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   2433\u001b[0m     visitorcallable: Type[Union[SchemaGenerator, SchemaDropper]],\n\u001b[0;32m   2434\u001b[0m     element: SchemaItem,\n\u001b[0;32m   2435\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[0;32m   2436\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2437\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"run a DDL visitor.\u001b[39;00m\n\u001b[0;32m   2438\u001b[0m \n\u001b[0;32m   2439\u001b[0m \u001b[39m    This method is only here so that the MockConnection can change the\u001b[39;00m\n\u001b[0;32m   2440\u001b[0m \u001b[39m    options given to the visitor so that \"checkfirst\" is skipped.\u001b[39;00m\n\u001b[0;32m   2441\u001b[0m \n\u001b[0;32m   2442\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2443\u001b[0m     visitorcallable(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdialect, \u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\u001b[39m.\u001b[39;49mtraverse_single(element)\n",
      "File \u001b[1;32mc:\\Users\\kthuv\\.conda\\envs\\mrdc\\Lib\\site-packages\\sqlalchemy\\sql\\visitors.py:670\u001b[0m, in \u001b[0;36mExternalTraversal.traverse_single\u001b[1;34m(self, obj, **kw)\u001b[0m\n\u001b[0;32m    668\u001b[0m meth \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(v, \u001b[39m\"\u001b[39m\u001b[39mvisit_\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m obj\u001b[39m.\u001b[39m__visit_name__, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    669\u001b[0m \u001b[39mif\u001b[39;00m meth:\n\u001b[1;32m--> 670\u001b[0m     \u001b[39mreturn\u001b[39;00m meth(obj, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[1;32mc:\\Users\\kthuv\\.conda\\envs\\mrdc\\Lib\\site-packages\\sqlalchemy\\sql\\ddl.py:1145\u001b[0m, in \u001b[0;36mSchemaDropper.visit_table\u001b[1;34m(self, table, drop_ok, _is_metadata_operation, _ignore_sequences)\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m   1140\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwith_ddl_events(\n\u001b[0;32m   1141\u001b[0m     table,\n\u001b[0;32m   1142\u001b[0m     checkfirst\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheckfirst,\n\u001b[0;32m   1143\u001b[0m     _is_metadata_operation\u001b[39m=\u001b[39m_is_metadata_operation,\n\u001b[0;32m   1144\u001b[0m ):\n\u001b[1;32m-> 1145\u001b[0m     DropTable(table)\u001b[39m.\u001b[39;49m_invoke_with(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconnection)\n\u001b[0;32m   1147\u001b[0m     \u001b[39m# traverse client side defaults which may refer to server-side\u001b[39;00m\n\u001b[0;32m   1148\u001b[0m     \u001b[39m# sequences. noting that some of these client side defaults may\u001b[39;00m\n\u001b[0;32m   1149\u001b[0m     \u001b[39m# also be set up as server side defaults\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1152\u001b[0m     \u001b[39m# #associating-a-sequence-as-the-server-side-\u001b[39;00m\n\u001b[0;32m   1153\u001b[0m     \u001b[39m# default), so have to be dropped after the table is dropped.\u001b[39;00m\n\u001b[0;32m   1154\u001b[0m     \u001b[39mfor\u001b[39;00m column \u001b[39min\u001b[39;00m table\u001b[39m.\u001b[39mcolumns:\n",
      "File \u001b[1;32mc:\\Users\\kthuv\\.conda\\envs\\mrdc\\Lib\\site-packages\\sqlalchemy\\sql\\ddl.py:315\u001b[0m, in \u001b[0;36mExecutableDDLElement._invoke_with\u001b[1;34m(self, bind)\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_invoke_with\u001b[39m(\u001b[39mself\u001b[39m, bind):\n\u001b[0;32m    314\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_execute(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget, bind):\n\u001b[1;32m--> 315\u001b[0m         \u001b[39mreturn\u001b[39;00m bind\u001b[39m.\u001b[39;49mexecute(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\kthuv\\.conda\\envs\\mrdc\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1412\u001b[0m, in \u001b[0;36mConnection.execute\u001b[1;34m(self, statement, parameters, execution_options)\u001b[0m\n\u001b[0;32m   1410\u001b[0m     \u001b[39mraise\u001b[39;00m exc\u001b[39m.\u001b[39mObjectNotExecutableError(statement) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   1411\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1412\u001b[0m     \u001b[39mreturn\u001b[39;00m meth(\n\u001b[0;32m   1413\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   1414\u001b[0m         distilled_parameters,\n\u001b[0;32m   1415\u001b[0m         execution_options \u001b[39mor\u001b[39;49;00m NO_OPTIONS,\n\u001b[0;32m   1416\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\kthuv\\.conda\\envs\\mrdc\\Lib\\site-packages\\sqlalchemy\\sql\\ddl.py:181\u001b[0m, in \u001b[0;36mExecutableDDLElement._execute_on_connection\u001b[1;34m(self, connection, distilled_params, execution_options)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_execute_on_connection\u001b[39m(\n\u001b[0;32m    179\u001b[0m     \u001b[39mself\u001b[39m, connection, distilled_params, execution_options\n\u001b[0;32m    180\u001b[0m ):\n\u001b[1;32m--> 181\u001b[0m     \u001b[39mreturn\u001b[39;00m connection\u001b[39m.\u001b[39;49m_execute_ddl(\n\u001b[0;32m    182\u001b[0m         \u001b[39mself\u001b[39;49m, distilled_params, execution_options\n\u001b[0;32m    183\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\kthuv\\.conda\\envs\\mrdc\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1524\u001b[0m, in \u001b[0;36mConnection._execute_ddl\u001b[1;34m(self, ddl, distilled_parameters, execution_options)\u001b[0m\n\u001b[0;32m   1519\u001b[0m dialect \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdialect\n\u001b[0;32m   1521\u001b[0m compiled \u001b[39m=\u001b[39m ddl\u001b[39m.\u001b[39mcompile(\n\u001b[0;32m   1522\u001b[0m     dialect\u001b[39m=\u001b[39mdialect, schema_translate_map\u001b[39m=\u001b[39mschema_translate_map\n\u001b[0;32m   1523\u001b[0m )\n\u001b[1;32m-> 1524\u001b[0m ret \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_context(\n\u001b[0;32m   1525\u001b[0m     dialect,\n\u001b[0;32m   1526\u001b[0m     dialect\u001b[39m.\u001b[39;49mexecution_ctx_cls\u001b[39m.\u001b[39;49m_init_ddl,\n\u001b[0;32m   1527\u001b[0m     compiled,\n\u001b[0;32m   1528\u001b[0m     \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m   1529\u001b[0m     execution_options,\n\u001b[0;32m   1530\u001b[0m     compiled,\n\u001b[0;32m   1531\u001b[0m )\n\u001b[0;32m   1532\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_events \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine\u001b[39m.\u001b[39m_has_events:\n\u001b[0;32m   1533\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mafter_execute(\n\u001b[0;32m   1534\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[0;32m   1535\u001b[0m         ddl,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1539\u001b[0m         ret,\n\u001b[0;32m   1540\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\kthuv\\.conda\\envs\\mrdc\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1844\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[1;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[0;32m   1839\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exec_insertmany_context(\n\u001b[0;32m   1840\u001b[0m         dialect,\n\u001b[0;32m   1841\u001b[0m         context,\n\u001b[0;32m   1842\u001b[0m     )\n\u001b[0;32m   1843\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1844\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_exec_single_context(\n\u001b[0;32m   1845\u001b[0m         dialect, context, statement, parameters\n\u001b[0;32m   1846\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\kthuv\\.conda\\envs\\mrdc\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1984\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[1;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[0;32m   1981\u001b[0m     result \u001b[39m=\u001b[39m context\u001b[39m.\u001b[39m_setup_result_proxy()\n\u001b[0;32m   1983\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m-> 1984\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_handle_dbapi_exception(\n\u001b[0;32m   1985\u001b[0m         e, str_statement, effective_parameters, cursor, context\n\u001b[0;32m   1986\u001b[0m     )\n\u001b[0;32m   1988\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\kthuv\\.conda\\envs\\mrdc\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:2339\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[1;34m(self, e, statement, parameters, cursor, context, is_sub_exec)\u001b[0m\n\u001b[0;32m   2337\u001b[0m \u001b[39melif\u001b[39;00m should_wrap:\n\u001b[0;32m   2338\u001b[0m     \u001b[39massert\u001b[39;00m sqlalchemy_exception \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 2339\u001b[0m     \u001b[39mraise\u001b[39;00m sqlalchemy_exception\u001b[39m.\u001b[39mwith_traceback(exc_info[\u001b[39m2\u001b[39m]) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m   2340\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2341\u001b[0m     \u001b[39massert\u001b[39;00m exc_info[\u001b[39m1\u001b[39m] \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kthuv\\.conda\\envs\\mrdc\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1965\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[1;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[0;32m   1963\u001b[0m                 \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m   1964\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m evt_handled:\n\u001b[1;32m-> 1965\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdialect\u001b[39m.\u001b[39;49mdo_execute(\n\u001b[0;32m   1966\u001b[0m             cursor, str_statement, effective_parameters, context\n\u001b[0;32m   1967\u001b[0m         )\n\u001b[0;32m   1969\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_events \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine\u001b[39m.\u001b[39m_has_events:\n\u001b[0;32m   1970\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mafter_cursor_execute(\n\u001b[0;32m   1971\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[0;32m   1972\u001b[0m         cursor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1976\u001b[0m         context\u001b[39m.\u001b[39mexecutemany,\n\u001b[0;32m   1977\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\kthuv\\.conda\\envs\\mrdc\\Lib\\site-packages\\sqlalchemy\\engine\\default.py:921\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[1;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[0;32m    920\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdo_execute\u001b[39m(\u001b[39mself\u001b[39m, cursor, statement, parameters, context\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m--> 921\u001b[0m     cursor\u001b[39m.\u001b[39;49mexecute(statement, parameters)\n",
      "\u001b[1;31mInternalError\u001b[0m: (psycopg2.errors.DependentObjectsStillExist) cannot drop table dim_card_details because other objects depend on it\nDETAIL:  constraint orders_card_number_id on table orders_table depends on table dim_card_details\nHINT:  Use DROP ... CASCADE to drop the dependent objects too.\n\n[SQL: \nDROP TABLE dim_card_details]\n(Background on this error at: https://sqlalche.me/e/20/2j85)"
     ]
    }
   ],
   "source": [
    "pdf_file = DataExtractor().retrieve_pdf_data(\"https://data-handling-public.s3.eu-west-1.amazonaws.com/card_details.pdf\")\n",
    "data_pdf = DataCleaning(dataframe=pdf_file).clean_card_data()\n",
    "card_details_to_sql = DatabaseConnector(file='sales_data_creds.yaml').upload_to_db(data_pdf, 'dim_card_details')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'x-api-key': 'yFBQbwXe9J3sd6zWVAMrK6lcxxr0q1lr2PT6DDMX'}\n",
    "\n",
    "number_of_stores = DataExtractor().list_number_of_stores('https://aqj7u5id95.execute-api.eu-west-1.amazonaws.com/prod/number_stores', headers)\n",
    "stores_data = DataExtractor().retrieve_stores_data(f'https://aqj7u5id95.execute-api.eu-west-1.amazonaws.com/prod/store_details/', number_of_stores, headers)\n",
    "\n",
    "stores_data_clean = DataCleaning(stores_data).clean_store_data()\n",
    "store_data_to_sql = DatabaseConnector('sales_data_creds.yaml').upload_to_db(stores_data_clean, 'dim_store_details')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import s3fs\n",
    "#def extract_from_s3(s3_resource):\n",
    "    #df = pd.read_csv(s3_resource, index_col=0)\n",
    "    #return df\n",
    "\n",
    "#s3_df = extract_from_s3('s3://data-handling-public/products.csv')\n",
    "#s3_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kthuv\\AppData\\Local\\Temp\\ipykernel_7000\\3486025887.py:154: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.dataframe['weight'] = self.dataframe['weight'].replace(replacements, regex=True)\n",
      "C:\\Users\\kthuv\\AppData\\Local\\Temp\\ipykernel_7000\\3486025887.py:155: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.dataframe['weight'] = self.dataframe['weight'].str.replace('77/1000 .', '77/1000', regex=True)\n",
      "C:\\Users\\kthuv\\AppData\\Local\\Temp\\ipykernel_7000\\3486025887.py:156: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.dataframe['weight'] = self.dataframe['weight'].apply(lambda x: eval(str(x))).astype(float)\n"
     ]
    }
   ],
   "source": [
    "# Use the local_path in the function\n",
    "s3_df = DataExtractor().extract_from_s3_csv('s3://data-handling-public/products.csv', local_path = '/Users/kthuv/AiCore/Projects/MRDC/products.csv')\n",
    "\n",
    "s3_data_df = DataCleaning(s3_df).clean_products_data()\n",
    "\n",
    "products_df = DatabaseConnector(file='sales_data_creds.yaml').upload_to_db(s3_data_df, 'dim_products')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_database = DatabaseConnector(file='db_creds.yaml').init_db_engine()\n",
    "orders_data_df = DataExtractor(yaml_database).read_rds_table('orders_table')\n",
    "cleaned_order_df = DataCleaning(orders_data_df).clean_orders_data()\n",
    "orders_data_to_sql = DatabaseConnector(file='sales_data_creds.yaml').upload_to_db(cleaned_order_df, 'orders_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "s3_json_df = DataExtractor().extract_from_s3_json('s3://data-handling-public/date_details.json', local_path = '/Users/kthuv/AiCore/Projects/MRDC/date_details.json')\n",
    "date_times_cleaned = DataCleaning(s3_json_df).clean_date_times()\n",
    "date_times_to_sql = DatabaseConnector(file='sales_data_creds.yaml').upload_to_db(date_times_cleaned, 'dim_date_times')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_number</th>\n",
       "      <th>expiry_date</th>\n",
       "      <th>card_provider</th>\n",
       "      <th>date_payment_confirmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6667</th>\n",
       "      <td>4534746397893770</td>\n",
       "      <td>01/30</td>\n",
       "      <td>VISA 16 digit</td>\n",
       "      <td>December 2000 01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           card_number expiry_date  card_provider date_payment_confirmed\n",
       "6667  4534746397893770       01/30  VISA 16 digit       December 2000 01"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_file[pdf_file['card_number'].astype(str).apply(lambda x: '4534746397893770' in str(x))]\n",
    "#data_pdf[data_pdf['card_number']=='4971858637664481']\n",
    "\n",
    "#data_pdf['card_provider'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_number</th>\n",
       "      <th>expiry_date</th>\n",
       "      <th>card_provider</th>\n",
       "      <th>date_payment_confirmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6667</th>\n",
       "      <td>4534746397893770</td>\n",
       "      <td>2030-01-01 00:00:00</td>\n",
       "      <td>VISA 16 digit</td>\n",
       "      <td>2000-12-01 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           card_number          expiry_date  card_provider  \\\n",
       "6667  4534746397893770  2030-01-01 00:00:00  VISA 16 digit   \n",
       "\n",
       "     date_payment_confirmed  \n",
       "6667    2000-12-01 00:00:00  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pdf[data_pdf['card_number'].astype(str).apply(lambda x: '4534746397893770' in str(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>longitude</th>\n",
       "      <th>lat</th>\n",
       "      <th>locality</th>\n",
       "      <th>store_code</th>\n",
       "      <th>staff_numbers</th>\n",
       "      <th>opening_date</th>\n",
       "      <th>store_type</th>\n",
       "      <th>latitude</th>\n",
       "      <th>country_code</th>\n",
       "      <th>continent</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>Tröstplatz 5\\n15926 Wittmund, Pfullingen</td>\n",
       "      <td>48.46458</td>\n",
       "      <td>None</td>\n",
       "      <td>Pfullingen</td>\n",
       "      <td>PF-F95902BC</td>\n",
       "      <td>23</td>\n",
       "      <td>2018-05-26</td>\n",
       "      <td>Local</td>\n",
       "      <td>9.22796</td>\n",
       "      <td>DE</td>\n",
       "      <td>eeEurope</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        address longitude   lat    locality  \\\n",
       "index                                                                         \n",
       "155    Tröstplatz 5\\n15926 Wittmund, Pfullingen  48.46458  None  Pfullingen   \n",
       "\n",
       "        store_code staff_numbers opening_date store_type latitude  \\\n",
       "index                                                               \n",
       "155    PF-F95902BC            23   2018-05-26      Local  9.22796   \n",
       "\n",
       "      country_code continent  \n",
       "index                         \n",
       "155             DE  eeEurope  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stores_data[stores_data['store_code'].astype(str).apply(lambda x: '2BC' in str(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>longitude</th>\n",
       "      <th>locality</th>\n",
       "      <th>store_code</th>\n",
       "      <th>staff_numbers</th>\n",
       "      <th>opening_date</th>\n",
       "      <th>store_type</th>\n",
       "      <th>latitude</th>\n",
       "      <th>country_code</th>\n",
       "      <th>continent</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>Tröstplatz 5\\n15926 Wittmund, Pfullingen</td>\n",
       "      <td>48.46458</td>\n",
       "      <td>Pfullingen</td>\n",
       "      <td>PF-F95902BC</td>\n",
       "      <td>23</td>\n",
       "      <td>2018-05-26 00:00:00</td>\n",
       "      <td>Local</td>\n",
       "      <td>9.22796</td>\n",
       "      <td>DE</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        address longitude    locality  \\\n",
       "index                                                                   \n",
       "155    Tröstplatz 5\\n15926 Wittmund, Pfullingen  48.46458  Pfullingen   \n",
       "\n",
       "        store_code staff_numbers         opening_date store_type latitude  \\\n",
       "index                                                                       \n",
       "155    PF-F95902BC            23  2018-05-26 00:00:00      Local  9.22796   \n",
       "\n",
       "      country_code continent  \n",
       "index                         \n",
       "155             DE    Europe  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stores_data_clean[stores_data_clean['store_code'].astype(str).apply(lambda x: '2BC' in str(x))]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mrdc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
